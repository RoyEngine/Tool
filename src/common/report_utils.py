#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šå·¥å…·æ¨¡å—

è¯¥æ¨¡å—åŒ…å«æŠ¥å‘Šç”Ÿæˆå’Œä¿å­˜åŠŸèƒ½ã€‚
"""

import json
import os
from typing import Any, Dict, Optional

from .timestamp_utils import get_formatted_timestamp


def generate_report(
    process_id: str,
    mode: str,
    sub_flow: str,
    status: str,
    data: Dict[str, Any],
    decompile: Optional[Dict[str, str]] = None,
) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ¥å‘Š

    Args:
        process_id: å¤„ç†ID
        mode: æ¨¡å¼(Extractæˆ–Extend)
        sub_flow: å­æµç¨‹
        status: çŠ¶æ€(successæˆ–fail)
        data: æ•°æ®
        decompile: åç¼–è¯‘ä¿¡æ¯(å¯é€‰)

    Returns:
        Dict[str, Any]: æŠ¥å‘Šæ•°æ®
    """
    # è·å–å½“å‰æ—¶é—´
    start_time = get_formatted_timestamp()
    end_time = get_formatted_timestamp()

    # æ„å»ºæŠ¥å‘Šç»“æ„
    report = {
        "process_id": process_id,
        "mode": mode,
        "sub_flow": sub_flow,
        "start_time": start_time,
        "end_time": end_time,
        "status": status,
        "data": data,
    }

    # å¦‚æœæœ‰åç¼–è¯‘ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æŠ¥å‘Šä¸­
    if decompile:
        report["decompile"] = decompile

    return report


def save_report(report: Dict[str, Any], report_path: str, timestamp: str, rule_type: str = None, mod_name: str = None, language: str = None) -> bool:
    """
    ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

    Args:
        report: æŠ¥å‘Šæ•°æ®
        report_path: æŠ¥å‘Šä¿å­˜è·¯å¾„
        timestamp: æ—¶é—´æˆ³
        rule_type: è§„åˆ™ç±»å‹(regular: å¸¸è§„æå–è§„åˆ™, mapping: æ˜ å°„è§„åˆ™)
        mod_name: æ¨¡ç»„åç§°
        language: è¯­è¨€ç±»å‹(Englishæˆ–Chinese)

    Returns:
        bool: æ˜¯å¦æˆåŠŸä¿å­˜
    """
    try:
        # æ ¹æ®è§„åˆ™ç±»å‹ç¡®å®šåŸºç¡€æŠ¥å‘Šä¿å­˜è·¯å¾„
        base_report_path = report_path
        
        # åˆ¤æ–­æ˜¯å•ä¸ªæ–‡ä»¶è¿˜æ˜¯å¤šä¸ªæ–‡ä»¶å¤„ç†
        is_single_file = False
        data = report.get("data", {})
        total_count = data.get("total_count", 1)
        
        # æ£€æŸ¥total_countï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºå•ä¸ªæ–‡ä»¶å¤„ç†
        if total_count == 1:
            is_single_file = True
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå•ä¸ªJARæ–‡ä»¶åç¼–è¯‘æŠ¥å‘Š
        if report.get("sub_flow") == "åç¼–è¯‘å•ä¸ªJARæ–‡ä»¶":
            is_single_file = True
        
        # ç¡®å®šæœ€ç»ˆæŠ¥å‘Šä¿å­˜è·¯å¾„
        if is_single_file:
            # å•ä¸ªæ–‡ä»¶å¤„ç†ï¼Œç›´æ¥ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹æ ¹ç›®å½•
            final_report_path = base_report_path
        else:
            # å¤šä¸ªæ–‡ä»¶å¤„ç†ï¼Œç»Ÿä¸€ä¿å­˜åˆ°Reportæ–‡ä»¶å¤¹å†…
            final_report_path = os.path.join(base_report_path, "Report")
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs(final_report_path, exist_ok=True)

        # æ„å»ºæŠ¥å‘Šæ–‡ä»¶å
        report_file = os.path.join(
            final_report_path, f"{report['mode'].lower()}_{timestamp}_report.json"
        )

        # ä¿å­˜æŠ¥å‘Š
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"[OK] æŠ¥å‘Šä¿å­˜æˆåŠŸ: {report_file}")
        return True
    except Exception as e:
        print(f"[ERROR] æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
        return False


def update_report_status(
    report: Dict[str, Any], status: str, data: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ›´æ–°æŠ¥å‘ŠçŠ¶æ€

    Args:
        report: æŠ¥å‘Šæ•°æ®
        status: æ–°çŠ¶æ€
        data: æ–°æ•°æ®(å¯é€‰)

    Returns:
        Dict[str, Any]: æ›´æ–°åçš„æŠ¥å‘Šæ•°æ®
    """
    # æ›´æ–°çŠ¶æ€
    report["status"] = status

    # æ›´æ–°ç»“æŸæ—¶é—´
    report["end_time"] = get_formatted_timestamp()

    # å¦‚æœæœ‰æ–°æ•°æ®ï¼Œæ›´æ–°æ•°æ®
    if data:
        report["data"].update(data)

    return report


def get_report_summary(report: Dict[str, Any]) -> str:
    """
    è·å–æŠ¥å‘Šæ‘˜è¦

    Args:
        report: æŠ¥å‘Šæ•°æ®

    Returns:
        str: æŠ¥å‘Šæ‘˜è¦
    """
    summary = f"""
ğŸ“‹ æŠ¥å‘Šæ‘˜è¦
==========
æ¨¡å¼: {report['mode']}
å­æµç¨‹: {report['sub_flow']}
çŠ¶æ€: {report['status']}
å¼€å§‹æ—¶é—´: {report['start_time']}
ç»“æŸæ—¶é—´: {report['end_time']}
å¤„ç†ID: {report['process_id']}

æ•°æ®ç»Ÿè®¡:
- æ€»æ•°é‡: {report['data'].get('total_count', 0)}
- æˆåŠŸæ•°é‡: {report['data'].get('success_count', 0)}
- å¤±è´¥æ•°é‡: {report['data'].get('fail_count', 0)}
"""

    # å¦‚æœæœ‰åç¼–è¯‘ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æ‘˜è¦ä¸­
    if "decompile" in report:
        summary += "\nåç¼–è¯‘ä¿¡æ¯:\n"
        summary += f"- JARè·¯å¾„: {report['decompile'].get('jar_path', 'N/A')}\n"
        summary += f"- çŠ¶æ€: {report['decompile'].get('status', 'N/A')}"

    return summary


def merge_reports(reports: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    åˆå¹¶å¤šä¸ªæŠ¥å‘Šä¸ºä¸€ä¸ªæŠ¥å‘Š

    Args:
        reports: æŠ¥å‘Šåˆ—è¡¨

    Returns:
        Dict[str, Any]: åˆå¹¶åçš„æŠ¥å‘Š
    """
    if not reports:
        return {}

    # åˆå¹¶æŠ¥å‘Šæ•°æ®
    merged_data = {
        "total_count": 0,
        "success_count": 0,
        "fail_count": 0,
        "fail_reasons": []
    }

    # æ”¶é›†æ‰€æœ‰å¤±è´¥åŸå› 
    fail_reasons = []

    # ç»Ÿè®¡æ•°æ®
    for report in reports:
        data = report.get("data", {})
        merged_data["total_count"] += data.get("total_count", 0)
        merged_data["success_count"] += data.get("success_count", 0)
        merged_data["fail_count"] += data.get("fail_count", 0)
        fail_reasons.extend(data.get("fail_reasons", []))

    # å»é‡å¤±è´¥åŸå› 
    merged_data["fail_reasons"] = list(set(fail_reasons))

    # ç¡®å®šæ•´ä½“çŠ¶æ€
    overall_status = "success" if merged_data["fail_count"] == 0 else "fail"

    # æ„å»ºåˆå¹¶åçš„æŠ¥å‘Š
    merged_report = {
        "process_id": reports[0]["process_id"],
        "mode": reports[0]["mode"],
        "sub_flow": "åˆå¹¶æŠ¥å‘Š",
        "start_time": min(report["start_time"] for report in reports),
        "end_time": max(report["end_time"] for report in reports),
        "status": overall_status,
        "data": merged_data,
        "sub_reports": reports
    }

    return merged_report


def find_reports(directory: str, mode: Optional[str] = None, status: Optional[str] = None, start_time: Optional[str] = None, end_time: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    æŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„æŠ¥å‘Š

    Args:
        directory: æŠ¥å‘Šç›®å½•
        mode: æ¨¡å¼(å¯é€‰)
        status: çŠ¶æ€(å¯é€‰)
        start_time: å¼€å§‹æ—¶é—´(å¯é€‰)
        end_time: ç»“æŸæ—¶é—´(å¯é€‰)

    Returns:
        List[Dict[str, Any]]: ç¬¦åˆæ¡ä»¶çš„æŠ¥å‘Šåˆ—è¡¨
    """
    reports = []

    # éå†ç›®å½•ä¸‹æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith("_report.json"):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        report = json.load(f)
                    
                    # æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦ç¬¦åˆæ¡ä»¶
                    match = True
                    
                    # æ£€æŸ¥æ¨¡å¼
                    if mode and report.get("mode", "") != mode:
                        match = False
                    
                    # æ£€æŸ¥çŠ¶æ€
                    if status and report.get("status", "") != status:
                        match = False
                    
                    # æ£€æŸ¥å¼€å§‹æ—¶é—´
                    if start_time and report.get("start_time", "") < start_time:
                        match = False
                    
                    # æ£€æŸ¥ç»“æŸæ—¶é—´
                    if end_time and report.get("end_time", "") > end_time:
                        match = False
                    
                    if match:
                        reports.append(report)
                except Exception as e:
                    print(f"[ERROR] è¯»å–æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {file_path} - {e}")
    
    return reports


def generate_report_statistics(reports: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯

    Args:
        reports: æŠ¥å‘Šåˆ—è¡¨

    Returns:
        Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
    """
    if not reports:
        return {}

    # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
    stats = {
        "total_reports": len(reports),
        "success_reports": 0,
        "fail_reports": 0,
        "total_processed": 0,
        "total_success": 0,
        "total_fail": 0,
        "mode_distribution": {},
        "status_distribution": {}
    }

    # ç»Ÿè®¡æ•°æ®
    for report in reports:
        # ç»Ÿè®¡æŠ¥å‘ŠçŠ¶æ€
        status = report.get("status", "")
        if status == "success":
            stats["success_reports"] += 1
        else:
            stats["fail_reports"] += 1
        
        # ç»Ÿè®¡æ¨¡å¼åˆ†å¸ƒ
        mode = report.get("mode", "")
        stats["mode_distribution"][mode] = stats["mode_distribution"].get(mode, 0) + 1
        
        # ç»Ÿè®¡çŠ¶æ€åˆ†å¸ƒ
        stats["status_distribution"][status] = stats["status_distribution"].get(status, 0) + 1
        
        # ç»Ÿè®¡å¤„ç†æ•°é‡
        data = report.get("data", {})
        stats["total_processed"] += data.get("total_count", 0)
        stats["total_success"] += data.get("success_count", 0)
        stats["total_fail"] += data.get("fail_count", 0)

    return stats


def export_report(report: Dict[str, Any], export_path: str, format: str = "json") -> bool:
    """
    å¯¼å‡ºæŠ¥å‘Šä¸ºä¸åŒæ ¼å¼

    Args:
        report: æŠ¥å‘Šæ•°æ®
        export_path: å¯¼å‡ºè·¯å¾„
        format: å¯¼å‡ºæ ¼å¼(json, txt, yaml)

    Returns:
        bool: æ˜¯å¦æˆåŠŸå¯¼å‡º
    """
    try:
        # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(export_path), exist_ok=True)
        
        if format == "json":
            # å¯¼å‡ºä¸ºJSONæ ¼å¼
            with open(export_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
        elif format == "txt":
            # å¯¼å‡ºä¸ºæ–‡æœ¬æ ¼å¼
            with open(export_path, "w", encoding="utf-8") as f:
                f.write(get_report_summary(report))
        elif format == "yaml":
            # å¯¼å‡ºä¸ºYAMLæ ¼å¼
            import yaml
            with open(export_path, "w", encoding="utf-8") as f:
                yaml.dump(report, f, allow_unicode=True, default_flow_style=False)
        else:
            print(f"[ERROR] ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
            return False
        
        print(f"[OK] æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {export_path}")
        return True
    except Exception as e:
        print(f"[ERROR] å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
        return False


def cleanup_old_reports(directory: str, days: int = 7) -> bool:
    """
    æ¸…ç†æŒ‡å®šå¤©æ•°å‰çš„æ—§æŠ¥å‘Š

    Args:
        directory: æŠ¥å‘Šç›®å½•
        days: ä¿ç•™å¤©æ•°

    Returns:
        bool: æ˜¯å¦æˆåŠŸæ¸…ç†
    """
    try:
        import time
        
        # è®¡ç®—è¿‡æœŸæ—¶é—´
        cutoff_time = time.time() - (days * 24 * 60 * 60)
        
        # éå†ç›®å½•ä¸‹æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
        deleted_count = 0
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.endswith("_report.json"):
                    file_path = os.path.join(root, file)
                    # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                    mtime = os.path.getmtime(file_path)
                    # å¦‚æœæ–‡ä»¶è¿‡æœŸï¼Œåˆ é™¤
                    if mtime < cutoff_time:
                        os.remove(file_path)
                        deleted_count += 1
        
        print(f"[OK] å·²æ¸…ç† {deleted_count} ä¸ªæ—§æŠ¥å‘Šæ–‡ä»¶")
        return True
    except Exception as e:
        print(f"[ERROR] æ¸…ç†æ—§æŠ¥å‘Šå¤±è´¥: {e}")
        return False
